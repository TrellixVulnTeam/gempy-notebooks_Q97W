{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_series(geo_model, series_df):\n",
    "    \"\"\"Updates series of the geo-model to the one stored in data.\"\"\"\n",
    "\n",
    "    series_old = list(geo_model.series.df.to_dict()['order_series'].keys())\n",
    "\n",
    "    # add new series\n",
    "    for index, row in series_df.iterrows():\n",
    "\n",
    "        serie_name = row['name']\n",
    "        if serie_name not in series_old:\n",
    "\n",
    "            geo_model.add_series(series_list=[serie_name])\n",
    "\n",
    "    # remove obsolete series\n",
    "    for serie in series_old:\n",
    "\n",
    "        if serie not in series_df['name'].to_list():\n",
    "\n",
    "            geo_model.delete_series(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_faults_relations(geo_model, series_df):\n",
    "    \"\"\"Sets fault relations.\"\"\"\n",
    "\n",
    "    for index, row in series_df.iterrows():\n",
    "\n",
    "        serie_name = row['name']\n",
    "        serie_isfault = row['isfault']\n",
    "        if serie_isfault:\n",
    "\n",
    "            geo_model.set_is_fault([serie_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_surfaces(geo_model, surfaces_df):\n",
    "    \"\"\"Updates surfaces of the geo-model to the one stored in data.\"\"\"\n",
    "\n",
    "    surfaces_old = geo_model.surfaces.df['surface'].to_list()\n",
    "\n",
    "    # add and update surfaces\n",
    "    for index, row in surfaces_df.iterrows():\n",
    "\n",
    "        surface_name = row['name']\n",
    "        surface_serie = row['serie']\n",
    "        if surface_name not in surfaces_old:\n",
    "\n",
    "            geo_model.add_surfaces(surface_list=[surface_name])\n",
    "            gp.map_series_to_surfaces(\n",
    "                geo_model,\n",
    "                {surface_serie: surface_name}\n",
    "            )\n",
    "\n",
    "        else:\n",
    "\n",
    "            gp.map_series_to_surfaces(\n",
    "                geo_model,\n",
    "                {surface_serie: surface_name}\n",
    "            )\n",
    "\n",
    "    # remove obsolete surfaces\n",
    "    for surface in surfaces_old:\n",
    "\n",
    "        if surface not in surfaces_df['name'].to_list():\n",
    "\n",
    "            geo_model.delete_surfaces(surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_realizations(geo_model, n_realizations, surface_points_original_df):\n",
    "    \n",
    "    # Copy geological input data to manipulate per realization.\n",
    "    surface_points_copy = copy.deepcopy(surface_points_original_df)\n",
    "    \n",
    "    # Storage for calucalted ralizations\n",
    "    list_section_data = []\n",
    "    \n",
    "    # TODO: Move Topological Realtaions updates to here\n",
    "    \n",
    "    # Calculate realizations\n",
    "    for i in range(n_realizations):\n",
    "        \n",
    "        # manipulate surface_points_copy in place\n",
    "        surface_points_copy['X'] = ss.norm.rvs(\n",
    "            loc=surface_points_original_df['X'].values,\n",
    "            scale=surface_points_original_df['param1'].values)\n",
    "        surface_points_copy['Y'] = ss.norm.rvs(\n",
    "            loc=surface_points_original_df['Y'].values,\n",
    "            scale=surface_points_original_df['param1'].values)\n",
    "        surface_points_copy['Z'] = ss.norm.rvs(\n",
    "            loc=surface_points_original_df['Z'].values,\n",
    "            scale=surface_points_original_df['param1'].values)\n",
    "        \n",
    "        # Data to model\n",
    "        # TODO: Replace with function\n",
    "        gp.init_data(\n",
    "            geo_model,\n",
    "            extent=[0, 2000, 0, 2000, 0, 2000],\n",
    "            resolution=[5, 5, 5],\n",
    "            surface_points_df=surface_points_copy,\n",
    "            orientations_df=orientations_df,\n",
    "            update_surfaces=False\n",
    "        )\n",
    "\n",
    "        # Set fault realtions\n",
    "        for index, row in series_df.iterrows():\n",
    "\n",
    "            serie_name = row['name']\n",
    "            serie_isfault = row['isfault']        \n",
    "            if serie_isfault:\n",
    "\n",
    "                geo_model.set_is_fault([serie_name])\n",
    "                \n",
    "        # update to interpolator\n",
    "        geo_model.update_to_interpolator()\n",
    "        \n",
    "        # Set section grid  # Only one => client canvas\n",
    "        # TODO: Deactivate regular sectio  # Best case on init of geo_model\n",
    "        geo_model.set_section_grid(section_dict=section_dict)\n",
    "        \n",
    "        # Compute solution\n",
    "        # TODO: Fix bug!\n",
    "        # till here: until 90.1 ms for 1 realizations\n",
    "        # 213 m with 2x gp.compute_model()\n",
    "        solution = gp.compute_model(model=geo_model)\n",
    "        solution = gp.compute_model(model=geo_model)\n",
    "        \n",
    "        # collect extracted section data\n",
    "        list_section_data.append(geo_model \\\n",
    "            .solutions \\\n",
    "            .sections[0][0] \\\n",
    "            .reshape(section_dict['section'][2])\n",
    "        )\n",
    "        \n",
    "        return list_section_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_list_section_data(list_section_data):\n",
    "    \n",
    "    # Process results Stack results\n",
    "    section_data_stack = np.round(np.dstack(list_section_data))\n",
    "\n",
    "    # Get lithologies in stack\n",
    "    lithology_ids = np.unique(section_data_stack)\n",
    "    \n",
    "    return section_data_stack, lithology_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_lithology_occurrences_over_realizations(\n",
    "        section_data_stack,\n",
    "        lithology_ids,\n",
    "        section_dict\n",
    "):\n",
    "    \n",
    "    count_array = np.empty((\n",
    "        section_dict['section'][2][0],\n",
    "        section_dict['section'][2][1],\n",
    "        len(lithology_ids)))\n",
    "\n",
    "    for index, lithology in enumerate(lithology_ids):\n",
    "\n",
    "        count_array[:,:,index] = np.sum((\n",
    "            section_data_stack == lithology).astype(int), axis=2)\n",
    "        \n",
    "    return count_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_information_entropy(count_array, n_realizations):\n",
    "    \n",
    "    # Calculate information entropy\n",
    "    return ss.entropy(probability_array, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
