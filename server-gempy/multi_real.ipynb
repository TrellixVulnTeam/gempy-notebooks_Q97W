{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/namur/coding/notebooks/env/bin/python3\n"
     ]
    }
   ],
   "source": [
    "# standart libs\n",
    "import sys\n",
    "import random\n",
    "import copy\n",
    "from operator import itemgetter\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# 3rd party libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gempy as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from skimage import measure  # type: ignore\n",
    "\n",
    "\n",
    "\n",
    "# local\n",
    "import functions.realization_setup as real_setup\n",
    "import functions.realization_run as real_run\n",
    "import functions.post_processing as post_pro\n",
    "import functions.uq_runs as uq_runs\n",
    "\n",
    "# executable\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active grids: ['regular']\n",
      "Setting kriging parameters to their default values.\n",
      "Compiling theano function...\n",
      "Level of Optimization:  fast_run\n",
      "Device:  cpu\n",
      "Precision:  float64\n",
      "Number of faults:  0\n",
      "Compilation Done!\n",
      "Kriging values: \n",
      "                     values\n",
      "range              1.73205\n",
      "$C_o$            0.0714286\n",
      "drift equations        [3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gempy.core.interpolator.InterpolatorModel at 0x7f0dbc32def0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the geo_model\n",
    "geo_model = gp.create_model(\"GeoModel\")\n",
    "\n",
    "# defautl data\n",
    "geo_model = gp.init_data(\n",
    "    geo_model,\n",
    "    extent=[0, 1, 0, 1, 0, 1],\n",
    "    resolution=[1, 1, 1]\n",
    ")\n",
    "\n",
    "# compile theno function\n",
    "gp.set_interpolation_data(\n",
    "    geo_model,\n",
    "    compile_theano=True,\n",
    "    theano_optimizer='fast_run',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta\n",
    "geo_model_extent_1 = [0,1000,0,1000,0,1000]\n",
    "section_1 = {\n",
    "    'p1': [0, 500],\n",
    "    'p2': [1000, 500],\n",
    "    'resolution': [200, 200]\n",
    "}\n",
    "\n",
    "# sereis\n",
    "series_df_1 = pd.DataFrame(columns=['name', 'isfault', 'order_series'])\n",
    "series_df_1.loc[0] = { 'order_series': 0, 'name': 'Basement_Series', 'isfault': False }\n",
    "series_df_1.loc[1] = { 'order_series': 1, 'name': 'Strat_Series', 'isfault': False }\n",
    "\n",
    "# surfaces\n",
    "surfaces_df_1 = pd.DataFrame(columns=['name', 'serie', 'order_surface'])\n",
    "surfaces_df_1.loc[0] = { 'name': 'basement', 'serie': 'Basement_Series', 'order_surface': 0 }\n",
    "surfaces_df_1.loc[2] = { 'name': 'rock1', 'serie': 'Strat_Series', 'order_surface': 1 }\n",
    "surfaces_df_1.loc[1] = { 'name': 'rock2', 'serie': 'Strat_Series', 'order_surface': 2 }\n",
    "\n",
    "# geoData\n",
    "surface_points_input_data_1 = pd.read_csv('./data/model2_surface_points.csv')\n",
    "orientaions_input_data_1 = pd.read_csv('./data/model2_orientations.csv')\n",
    "\n",
    "# Format geological_input_data\n",
    "surface_points_original_df_1 = surface_points_input_data_1[['X', 'Y', 'Z', 'formation']]\n",
    "\n",
    "# rename colums\n",
    "surface_points_original_df_1.columns = ['X', 'Y', 'Z', 'surface']\n",
    "\n",
    "# add distribution type and parameter\n",
    "surface_points_original_df_1['param1'] = 10\n",
    "\n",
    "# Orientaions\n",
    "orientations_original_df_1 = orientaions_input_data_1[['X', 'Y', 'Z', 'dip', 'azimuth', 'polarity', 'formation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active grids: ['regular']\n",
      "Active grids: ['regular' 'sections']\n",
      "HOTFIX in update_series()\n",
      "HOTFIX in update_surfaces()\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "# setup model 1\n",
    "real_setup.setup_realization(\n",
    "        geo_model=geo_model,\n",
    "        geo_model_extent=geo_model_extent_1,\n",
    "        section=section_1,\n",
    "        series_df=series_df_1,\n",
    "        surfaces_df=surfaces_df_1,\n",
    "        surface_points_original_df=surface_points_original_df_1,\n",
    "        orientations_original_df=orientations_original_df_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run realizations setup checks until stable workflow.\n"
     ]
    }
   ],
   "source": [
    "if real_run.check_setup_single_realization(geo_model):\n",
    "    solution = gp.compute_model(model=geo_model, sort_surfaces=False)\n",
    "Bx = post_pro.compute_boolean_matrix_for_section_surface_top(geo_model)\n",
    "extent = { 'z_min': geo_model_extent_1[4], 'z_max': geo_model_extent_1[5] }\n",
    "section_coordinates = post_pro.compute_setction_grid_coordinates(geo_model, extent)\n",
    "tops_dict = post_pro.get_tops_coordinates(Bx, section_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_object = real_setup.creat_mapping_object(\n",
    "    series_df=series_df_1,\n",
    "    surfaces_df=surfaces_df_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realization 0 computed.\n",
      "Realization 1 computed.\n",
      "Realization 2 computed.\n",
      "Realization 3 computed.\n",
      "Realization 4 computed.\n",
      "Realization 5 computed.\n",
      "Realization 6 computed.\n",
      "Realization 7 computed.\n",
      "Realization 8 computed.\n",
      "Realization 9 computed.\n",
      "Realization 10 computed.\n",
      "Realization 11 computed.\n",
      "Realization 12 computed.\n",
      "Realization 13 computed.\n",
      "Realization 14 computed.\n",
      "Realization 15 computed.\n",
      "Realization 16 computed.\n",
      "Realization 17 computed.\n",
      "Realization 18 computed.\n",
      "Realization 19 computed.\n",
      "Realization 20 computed.\n",
      "Realization 21 computed.\n",
      "Realization 22 computed.\n",
      "Realization 23 computed.\n",
      "Realization 24 computed.\n",
      "Realization 25 computed.\n",
      "Realization 26 computed.\n",
      "Realization 27 computed.\n",
      "Realization 28 computed.\n",
      "Realization 29 computed.\n",
      "Realization 30 computed.\n",
      "Realization 31 computed.\n",
      "Realization 32 computed.\n",
      "Realization 33 computed.\n",
      "Realization 34 computed.\n",
      "Realization 35 computed.\n",
      "Realization 36 computed.\n",
      "Realization 37 computed.\n",
      "Realization 38 computed.\n",
      "Realization 39 computed.\n",
      "Realization 40 computed.\n",
      "Realization 41 computed.\n",
      "Realization 42 computed.\n",
      "Realization 43 computed.\n",
      "Realization 44 computed.\n",
      "Realization 45 computed.\n",
      "Realization 46 computed.\n",
      "Realization 47 computed.\n",
      "Realization 48 computed.\n",
      "Realization 49 computed.\n",
      "Realization 50 computed.\n",
      "Realization 51 computed.\n",
      "Realization 52 computed.\n",
      "Realization 53 computed.\n",
      "Realization 54 computed.\n",
      "Realization 55 computed.\n",
      "Realization 56 computed.\n",
      "Realization 57 computed.\n",
      "Realization 58 computed.\n",
      "Realization 59 computed.\n",
      "Realization 60 computed.\n",
      "Realization 61 computed.\n",
      "Realization 62 computed.\n",
      "Realization 63 computed.\n",
      "Realization 64 computed.\n",
      "Realization 65 computed.\n",
      "Realization 66 computed.\n",
      "Realization 67 computed.\n",
      "Realization 68 computed.\n"
     ]
    }
   ],
   "source": [
    "# Copy geological input data to manipulate per realization.\n",
    "surface_points_copy = copy.deepcopy(surface_points_original_df_1)\n",
    "contour_lst = {}\n",
    "\n",
    "for real_i in range (100): \n",
    "    \n",
    "        # manipulate surface_points_copy in place\n",
    "        uq_runs.manipulate_surface_points_inplace(\n",
    "            surface_points_copy=surface_points_copy,\n",
    "            surface_points_original_df=surface_points_original_df_1)\n",
    "        \n",
    "        # correct values outside range\n",
    "        for XYZ_i in ['X', 'Y', 'Z']:\n",
    "\n",
    "            if XYZ_i == 'X':\n",
    "                surface_points_copy['X'][surface_points_copy['X'] < geo_model_extent_1[0]] = geo_model_extent_1[0]\n",
    "                surface_points_copy['X'][surface_points_copy['X'] > geo_model_extent_1[1]] = geo_model_extent_1[1]\n",
    "\n",
    "            if XYZ_i == 'Y':\n",
    "                surface_points_copy['Y'][surface_points_copy['Y'] < geo_model_extent_1[2]] = geo_model_extent_1[2]\n",
    "                surface_points_copy['Y'][surface_points_copy['Y'] > geo_model_extent_1[3]] = geo_model_extent_1[3]\n",
    "\n",
    "            if XYZ_i == 'Z':\n",
    "                surface_points_copy['Z'][surface_points_copy['Z'] < geo_model_extent_1[4]] = geo_model_extent_1[4]\n",
    "                surface_points_copy['Z'][surface_points_copy['Z'] > geo_model_extent_1[5]] = geo_model_extent_1[5]\n",
    "        \n",
    "        # Set manipulated surface points\n",
    "        geo_model.set_surface_points(surface_points_copy, update_surfaces=False)\n",
    "        gp.map_series_to_surfaces(\n",
    "            geo_model=geo_model,\n",
    "            mapping_object=mapping_object\n",
    "        )\n",
    "\n",
    "        # update to interpolator\n",
    "        geo_model.update_to_interpolator()\n",
    "\n",
    "        # compute realization\n",
    "        try:\n",
    "            gp.compute_model(model=geo_model, sort_surfaces=False)\n",
    "            print(f'Realization {real_i} computed.')\n",
    "        except:\n",
    "            print(f'Error in realization {real_i}.')\n",
    "            pass\n",
    "        \n",
    "        # get contours\n",
    "        # get start and end of section in grid scalar vals array\n",
    "        arr_len_0, arr_len_n = geo_model.grid.sections.get_section_args('section')\n",
    "\n",
    "        # CAUTION: if more section present they have to be indexexed accrodingly;\n",
    "        # get shape of section  # 1st and only one here as only one section present.\n",
    "        section_shape = geo_model.grid.sections.resolution[0]\n",
    "        # extract section scalar values from solutions.sections# [series,serie_pos_0:serie_pos_n]\n",
    "        section_scalar_field_values = geo_model.solutions.sections[1][:,arr_len_0:arr_len_n]\n",
    "\n",
    "        # number scalar field blocks\n",
    "        n_scalar_field_blocks = section_scalar_field_values.shape[0]\n",
    "        # creat a dictionary to assemble all scalat field boolen matrices shifts\n",
    "        # extract transition towards current level\n",
    "        contours = {}\n",
    "        for block_i in range(n_scalar_field_blocks):\n",
    "\n",
    "            # number scalar field blocks\n",
    "            n_scalar_field_blocks = section_scalar_field_values.shape[0]\n",
    "            # creat a dictionary to assemble all scalat field boolen matrices shifts\n",
    "            # extract transition towards current level\n",
    "            contours = {}\n",
    "            for scalar_field_block_i in range(n_scalar_field_blocks):\n",
    "\n",
    "                # scalarfield values of scalarfield_block-i\n",
    "                block = section_scalar_field_values[scalar_field_block_i, :]\n",
    "                # ??? level\n",
    "                level = geo_model.solutions.scalar_field_at_surface_points[scalar_field_block_i][np.where(\n",
    "                    geo_model.solutions.scalar_field_at_surface_points[scalar_field_block_i] != 0)]\n",
    "                # ??? calulcate scalarfeild levels\n",
    "                levels = np.insert(level, 0, block.max())\n",
    "                # extract and reshape scalar field values\n",
    "                scalar_field = block.reshape(section_shape)\n",
    "                # loop over levels to extract tops present within current scalar field\n",
    "                for lvl_i in range(len(levels)):\n",
    "\n",
    "                    # get top name\n",
    "                    top_name = geo_model.surfaces.df['surface'][lvl_i]\n",
    "                    # Find contour\n",
    "                    contour = measure.find_contours(scalar_field, levels[lvl_i])\n",
    "                    # add contour to contoures if there are some\n",
    "                    if len(contour) > 0:\n",
    "\n",
    "                        contours[top_name] = contour[0]\n",
    "                        contour_lst[f'real_{real_i}_{top_name}'] = contour[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 20))\n",
    "for contour in contour_lst.keys():\n",
    "    ax.plot(\n",
    "        contour_lst[contour][:,0],\n",
    "        contour_lst[contour][:,1]   \n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
